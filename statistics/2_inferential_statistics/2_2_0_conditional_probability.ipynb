{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probability\n",
    "\n",
    "Events can be independent, i.e., one event doesn't have any influence on other events. But the world is complex and we do have situations where the occurrence of one event affects the probability of another event occurring. That's the idea behind conditional probability. What's the probability of event A happening given that event B has happened?\n",
    "\n",
    "## Sample space review\n",
    "\n",
    "We know that in classical probability in the case of independent events the sample space is collectively exhausted, i. e., for a given experiment the sample space contains all the possible outcomes. When we think about conditional probability where events are dependent on others, the sample space is still collectively exhausted, but it goes through a review since the set for all possible outcomes for the dependent event can become smaller. \n",
    "\n",
    "As always let's visualize this.\n",
    "\n",
    "374 people at a park were asked what was their favorite music style.\n",
    "\n",
    "| Favorite style | Female | Male | **Total** |\n",
    "|----------------|--------|------|-----------|\n",
    "| A: Rock        | 30     | 60   | 92        |\n",
    "| B: Country     | 45     | 27   | 72        |\n",
    "| C: Pop         | 64     | 39   | 103       |\n",
    "| D: Classical   | 65     | 42   | 107       |\n",
    "| **Total**      | 204    | 170  | 374       |\n",
    "\n",
    "\n",
    "$$ P(A) = \\frac{92}{374} = 0.2459 $$\n",
    "\n",
    "$$ P(F) = \\frac{204}{374} = 0.5454 $$\n",
    "\n",
    "But here is an interesting thing, if you use the multiplicative law to check the probability of being a rock fan and a female you get:\n",
    "\n",
    "$$ P(A \\cap F) = P(A) P(F) = 0.2459 \\times 0.5454 = 0.1341  $$\n",
    "\n",
    "Which is not the probability we got from the table above. This means both events are not independent. Why they are not independent? Well, because to be a female rock fan one event depend on the other.\n",
    "\n",
    "The language to express conditional probability is:\n",
    "\n",
    "$$ P(A|F) $$\n",
    "\n",
    "which means: given that the person is female what is the probability that the person is also a rock fan?\n",
    "\n",
    "$$ P(A|F) = \\frac{30}{204} = 0.1470 $$\n",
    "\n",
    "As you can see the sample space is revised. The conditioning event (being a female) changes the sample space (374 people) to 204 (total female), and from that 204 female, we know that 30 are rock fans. Now what we do is take the relative frequency and calculate the conditional probability.\n",
    "\n",
    "One other way to think about it is:\n",
    "\n",
    "$$ P(A|F) = \\frac{\\frac{30}{374}}{\\frac{204}{374}} = 0.1470 = \\frac{P(A \\cap F)}{P(F)} $$\n",
    "\n",
    "When we know that the conditioning event has occurred every outcome outside of F is discarded, that's why the sample space is reduced to the conditioning event, it's a revision of the original sample space. The only way the conditioned event can happen is when it intersects the conditioning event since that is our sample space.\n",
    "\n",
    "I like to think of conditional probability as a bowl full of balls. When you have a conditioning event you are not more interested in the whole bowl, but just a portion of those balls that met the condition and from that selection you go even further to select only the balls that met the event you are interested in. It's like filtering until you get what you want.\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./imgs/conditional_venn.png\" alt=\"Conditional probability\"/>\n",
    "</p>\n",
    "\n",
    "It's like: given that B happened, what portion of B intersects with the event I am interested in?\n",
    "\n",
    "## Probability trees\n",
    "\n",
    "Probability trees are a good way to visualize this filtering process until you find the probability of the conditioned event. You keep filtering until you reach the last branch, i. e., the conditioned event you are interested in and you just multiply all the probabilities you found along the way because you are interested in an event where all the previous probabilities of the previous branches will happen.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./imgs/cond_tree.png\" alt=\"Probability tree\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "> In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event.[1] For example, if the risk of developing health problems is known to increase with age, Bayes' theorem allows the risk to an individual of a known age to be assessed more accurately (by conditioning it on their age) than simply assuming that the individual is typical of the population as a whole. [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n",
    "\n",
    "The probability of one event happening, given a second event, is equal to the probability of both happening divided by the probability of the conditioning event.\n",
    "\n",
    "\n",
    "#### The simplest form\n",
    "\n",
    "## $$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$\n",
    "\n",
    "## $$ P(B|A) = \\frac{P(A \\cap B)}{P(A)} $$\n",
    "\n",
    "Multiply both sides by the conditioning event:\n",
    "\n",
    "## $$ P(A|B)P(B) = P(A \\cap B) $$\n",
    "\n",
    "## $$ P(B|A)P(A) = P(A \\cap B) $$\n",
    "\n",
    "\n",
    "## $$  P(A \\cap B) = P(B|A)P(A) = P(A|B)P(B)  $$\n",
    "\n",
    "which rearranging yields:\n",
    "\n",
    "## $$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total probability formula\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./imgs/total_prob.png\" alt=\"Conditional probability\"/>\n",
    "</p>\n",
    "\n",
    "The total probability rule (also called the Law of Total Probability) breaks up probability calculations into distinct parts. It's used to find the probability of an event, A,  when you don't know enough about A's probabilities to calculate it directly. This is useful because even though we might not know anything about the probability of event A, we may be able to calculate the probabilities of other events, which added together yield the total probability of A. This is with the use of conditional probability. Without the law of total probability, we may not be able to directly calculate any probabilities about which we werenâ€™t given information directly.\n",
    "\n",
    "## $$ P(A) = P(A\\,|\\,B)\\,P(B) + P(A\\,|\\,B^c)\\,P(B^c) $$\n",
    "\n",
    "The probability of event A is equal to its conditional probability on a second event times the probability of the second event, plus its probability conditional on the second event not occurring times the probability of that non-occurrence.\n",
    "\n",
    "This is what you can see in the diagram above. We might not know what's the probability of A, but we might add all the partitions (mutually exclusive and collectively exhaustive of A) that when summed up will yield all the probability of A happening.\n",
    "\n",
    "In the diagram above there are 4 partitions, but we can generalize the formula to account for any number of partitions:\n",
    "\n",
    "#### $$ \\begin{aligned} P(A) & = \\sum_{i=1}^n P(A\\,|\\,B_i)\\,P(B_i)\\\\[1ex] & = P(A\\,|\\,B_1)\\,P(B_1) + P(A\\,|\\,B_2)\\,P(B_2) + \\cdots + P(A\\,|\\,B_n)\\,P(B_n) \\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can recall the Bayes'formula to build up the knowledge to include the total probability formula in the calculation:\n",
    "\n",
    "### $$ P(A\\,|\\,B) = \\frac{P(B\\,|\\,A)\\,P(A)}{P(B\\,|\\,A)\\,P(A) + P(B\\,|\\,A^c)\\,P(A^c)} $$\n",
    "\n",
    "If we generalize for any number of partitions we have:\n",
    "\n",
    "## $$ P(A_k\\,|\\,B) = \\frac{P(B\\,|\\,A_k)\\,P(A_k)}{\\sum\\limits_{i=1}^n P(B\\,|\\,A_i)\\,P(A_i)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "1. \n",
    "\n",
    "$$ P(A) = 0.2 $$\n",
    "$$ P(B) = 0.25 $$\n",
    "$$ P(C) = 0.6 $$\n",
    "$$ P(A|B) = 0 $$\n",
    "$$ P(B|C) = 0.25 $$\n",
    "$$ P(C|A) = 0.2 $$\n",
    "\n",
    "**(a) Show that A and B are mutually exclusive**\n",
    "\n",
    "Events are mutually exclusive when they can't happen at the same time. $ P(A|B) = 0 $. This means that if B occurred A can't happen and vice-versa\n",
    "\n",
    "### $$ 0 = P(A\\,|\\,B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A \\cap B)}{0.25} $$\n",
    "\n",
    "**(b) Show that C does not imply A**\n",
    "\n",
    "By C implies A we mean that when C happens A necessarily will happen, i. e., $ P(A|C) = 1 $.\n",
    "\n",
    "### $$ P(A\\,|\\,C) = \\frac{P(C\\,|\\,A)\\,P(A)}{P(C)} = \\frac{0.2 \\times 0.2}{0.6} = 0.067 \\not= 1 $$\n",
    "\n",
    "Therefore C does not imply A.\n",
    "\n",
    "**(c) Probability $ P(B \\cup C) $**\n",
    "\n",
    "$ P(B \\cup C) = P(B) + P(C) - P(B\\cap C)  $\n",
    "\n",
    "$ P(B \\cup C) = 0.25 + 0.6 - P(B\\cap C)  $\n",
    "\n",
    "Following the Baye's theorem and rearraging it a bit:\n",
    "\n",
    "$ P(B\\cap C) = P(B|C)P(C) = 0.25 * 0.6 = 0.15  $\n",
    "\n",
    "$ P(B \\cup C) = 0.25 + 0.6 - 0.15 = 0.7   $\n",
    "\n",
    "**(d) Probability $ P(B|A) $**\n",
    "\n",
    "$ P(B|A) = \\frac{P(A \\cap B)}{P(A)} $\n",
    "\n",
    "$ P(A\\cap B) = P(A|B)P(B) = 0 * 0.25 = 0  $\n",
    "\n",
    "$ P(B|A) = \\frac{0}{0.2} = 0 $\n",
    "\n",
    "**(e) Probability $ P(B^c|C) $**\n",
    "\n",
    "$P(B^c|C) = 1 - P(B|C) = 1 - 0.25 = 0.75$\n",
    "\n",
    "-------------\n",
    "\n",
    "The company ABC is deciding whether to submit a bid to build a new shopping centre. In the past, ABC's main competitor, DEF, has submitted bids 70% of the time. If BBC does not bid for a job, the probability ABC will get the job is 50%. If BBC bids on a job, the probability that ABC will get the job reduces to 25% due to the competition.\n",
    "\n",
    "A = ABC gets the job\n",
    "\n",
    "B = DEF submits the bid\n",
    "\n",
    "$$ P(B) = 0.7 $$\n",
    "\n",
    "$$ P(B^c) = 0.3 $$\n",
    "\n",
    "$$ P(A|B^c) = 0.5 $$\n",
    "\n",
    "$$ P(A|B) = 0.25 $$\n",
    "\n",
    "\n",
    "**If ABC gets the job, what is the probability that DEF did not bid?**\n",
    "\n",
    "$ P(B^c|A) $\n",
    "\n",
    "First information we will need to calculate is P(A) and we can use the total probability formula to sum all the possible scenarios when ABC gets the job, i. e., when DEF bids and when DEF does not bid.\n",
    "\n",
    "$ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = 0.25 * 0.7 + 0.5 * 0.3 = 0.175 + 0.15 = 0.325 $\n",
    "\n",
    "$ P(B^c\\,|\\,A) = \\frac{P(A\\,|\\,B^c)\\,P(B^c)}{P(A\\,|\\,B)\\,P(B) + P(A\\,|\\,B^c)\\,P(B^c)} = \\frac{0.5 \\times 0.3}{0.25 \\times 0.7 + 0.5 \\times 0.3} = 0.4615 $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More resources\n",
    "\n",
    "I created a deck summarising what I cover in this Notebook:\n",
    "\n",
    "https://pitch.com/public/dc3f5807-6f0f-433f-8e7a-79359ff37171\n",
    "\n",
    "<iframe src=\"https://pitch.com/embed/dc3f5807-6f0f-433f-8e7a-79359ff37171\" allow=\"fullscreen\" allowfullscreen=\"\" width=\"560\" height=\"368\" style=\"border:0\"></iframe>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d7799eccdb3ea8e451c2948250ed2a26e30808e21a34f392c0240d03d9f38c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
